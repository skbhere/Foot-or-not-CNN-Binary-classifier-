{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsyCR83qNsbheDdV+wzoth",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skbhere/Foot-or-not-CNN-Binary-classifier-/blob/master/Transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnESmWqlg2jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pDO-4QUg6TX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2511eef8-847f-4d43-82fa-70d71afe432e"
      },
      "source": [
        "mobile = keras.applications.mobilenet.MobileNet()\n",
        "def prepare_image(file):\n",
        "    img_path = ''\n",
        "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Mm4fdtg-Lh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8bdde091-7dc7-4c78-8584-89f74399e784"
      },
      "source": [
        "preprocessed_image = prepare_image('Lighthouse.jpg')\n",
        "predictions = mobile.predict(preprocessed_image)\n",
        "results = imagenet_utils.decode_predictions(predictions)\n",
        "results"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02814860', 'beacon', 0.83203715),\n",
              "  ('n02980441', 'castle', 0.1304102),\n",
              "  ('n03781244', 'monastery', 0.012002675),\n",
              "  ('n03028079', 'church', 0.00917956),\n",
              "  ('n09399592', 'promontory', 0.0034800267)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgrgIt5EhGrJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "26667889-99ee-47a4-b31e-f6c9f4e19154"
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(2,activation='softmax')(x) #final layer with softmax activation"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPFeoPeXitt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFcBCDB3i1nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i,layer in enumerate(model.layers):\n",
        "#   # print(i,layer.name)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOopZltUjNS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "# or if we want to set the first 20 layers of the network to be non-trainable\n",
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qG9Zbuaj0Ke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41b682d9-faca-4a29-a2c3-4b99ff49c251"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rpXfOGIjl0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b46a3bf-7280-4565-fd49-e5de6dd4b853"
      },
      "source": [
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory('/content/drive/My Drive/data/foot or not/',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 293 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk88wFOLlOKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "b7bbaec8-9c6a-4f74-9718-68632898c6af"
      },
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-1d4221ccfbd2>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 53s 6s/step - loss: 0.8311 - accuracy: 0.8161\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0925 - accuracy: 0.9808\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0339 - accuracy: 0.9885\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0303 - accuracy: 0.9847\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0551 - accuracy: 0.9885\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0672 - accuracy: 0.9847\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 35s 4s/step - loss: 0.0500 - accuracy: 0.9861\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0495 - accuracy: 0.9732\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.1845 - accuracy: 0.9349\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.1585 - accuracy: 0.9732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f53f5dd1a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdmNmr_VlVMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "245e8abc-56a0-49d7-d403-30ab817510c6"
      },
      "source": [
        "def load_image(img_path, show=False):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    if show:\n",
        "        plt.imshow(img_tensor[0])                           \n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return img_tensor\n",
        "  \n",
        "#img_path = 'C:/Users/Ferhat/Python Code/Workshop/Tensoorflow transfer learning/blue_tit.jpg'\n",
        "img_path = '/content/122345.jpg'\n",
        "new_image = load_image(img_path)\n",
        "\n",
        "pred = model.predict(new_image)\n",
        "\n",
        "pred"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00, 3.0799998e-11]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QQQ51e3nZke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}